{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dc29a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pympler\n",
      "  Obtaining dependency information for pympler from https://files.pythonhosted.org/packages/79/4f/a6a2e2b202d7fd97eadfe90979845b8706676b41cbd3b42ba75adf329d1f/Pympler-1.1-py3-none-any.whl.metadata\n",
      "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\programdata\\anaconda3\\lib\\site-packages (from pympler) (305.1)\n",
      "Downloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
      "   ---------------------------------------- 0.0/165.8 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 71.7/165.8 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 165.8/165.8 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pympler\n",
      "Successfully installed pympler-1.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "!pip install pympler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1c314",
   "metadata": {},
   "source": [
    "# function reading the json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f1660ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13f121fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory: 5613.968750 KB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "from pympler import asizeof\n",
    "json2 = read_json_from_file('abscend.json')\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory: {size_in_mb:.6f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f1faa",
   "metadata": {},
   "source": [
    "# removing the Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28a3ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_slash_key(data, pattern=\"/key\"):\n",
    "    # Create a new dictionary to store the filtered results\n",
    "    new_dict = {}\n",
    "    \n",
    "    for k, v in data.items():\n",
    "        # If the key does not contain the pattern, add it to the new dictionary\n",
    "        if pattern not in k:\n",
    "            if isinstance(v, dict):\n",
    "                # Recursively apply the function if the value is a dictionary\n",
    "                new_dict[k] = filter_json_slash_key(v, pattern)\n",
    "            else:\n",
    "                # Otherwise, just add the key-value pair\n",
    "                new_dict[k] = v\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f76167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory: 2.802 MB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory: {size_in_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "988888c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_system_keys(data):\n",
    "    # Ensure we only modify the 'System' key if it exists\n",
    "    if 'System' in data:\n",
    "        # List of keys to remove from 'System'\n",
    "        keys_to_remove = ['Buffers', 'Transition', 'Flush', 'Tmp']\n",
    "        \n",
    "        # Loop through the list and remove each key from 'System' if it exists\n",
    "        for key in keys_to_remove:\n",
    "            data['System'].pop(key, None)\n",
    "    # Filter out entries that have \"last_written\" in the key\n",
    "    if isinstance(data, list):  # Check if data is a list of dictionaries\n",
    "        data = [entry for entry in data if \"/last_written\" not in entry.get(\"key\", \"\")]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1bc4709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 2.613380432128906 MB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.15f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e32a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_legacytrigger(data):\n",
    "    \"\"\"\n",
    "    This function recursively removes keys that match the pattern \"/Detectors/DetXX/Settings/LegacyTrigger\".\n",
    "    \"\"\"\n",
    "    def recursive_trim(d):\n",
    "        if isinstance(d, dict):\n",
    "            # Identify keys matching the specific pattern\n",
    "            keys_to_remove = [key for key in d if \"/Detectors/Det\" in key and \"/Settings/LegacyTrigger\" in key]\n",
    "            # Remove the matching keys\n",
    "            for key in keys_to_remove:\n",
    "                del d[key]\n",
    "            # Recursively process nested dictionaries or lists\n",
    "            for key, value in d.items():\n",
    "                if isinstance(value, (dict, list)):  # If the value is a dictionary or list, apply recursion\n",
    "                    recursive_trim(value)\n",
    "\n",
    "    # Call the recursive trim function on the data\n",
    "    recursive_trim(data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "45fd2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 2.613380432128906 MB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.15f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe8a0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing last_readout duplicate time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "462fb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_remove_duplicate_last_written(data):\n",
    "    seen_values = set()  # Stores unique \"last_written\" values\n",
    "\n",
    "    def recurse(d):\n",
    "        if isinstance(d, dict):\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, dict) and \"last_written\" in v:\n",
    "                    last_written_val = v[\"last_written\"]\n",
    "                    if last_written_val not in seen_values:\n",
    "                        seen_values.add(last_written_val)\n",
    "                        new_dict[k] = v  # Keep the first occurrence\n",
    "                else:\n",
    "                    # Recursively process nested dictionaries and lists\n",
    "                    new_dict[k] = recurse(v)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [recurse(item) for item in d]\n",
    "        return d\n",
    "\n",
    "    # First pass to collect duplicates\n",
    "    filtered_data = recurse(data)\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b22f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 2.613296508789062 MB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "json2 = filter_data_remove_duplicate_last_written(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.15f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1f74c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the last return!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d9a70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively remove keys ending with \"last_written\"\n",
    "def json_filter_remove_last_written(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: json_filter_remove_last_written(v) for k, v in data.items() if not k.endswith(\"last_written\")}\n",
    "    elif isinstance(data, list):\n",
    "        return [json_filter_remove_last_written(item) for item in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a9796eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 2.613 MB\n"
     ]
    }
   ],
   "source": [
    "#json1 = read_json_from_file('abcend (1).json')\n",
    "json2 = json_filter_remove_last_written(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0cf3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_json_differ_Readback_Setting(d):\n",
    "    \"\"\"\n",
    "    Filters out keys from the 'Settings' section of Detectors/DetXX if they match the values in the 'Readback' section.\n",
    "    Keeps the keys that differ between the 'Settings' and 'Readback' paths.\n",
    "    \"\"\"\n",
    "    def recurse(d, readback_data, settings_data, path=\"\"):\n",
    "        \"\"\"\n",
    "        Recursive function to traverse and compare the two paths.\n",
    "        - d: the current data (settings or readback)\n",
    "        - readback_data: the current data from the Readback section\n",
    "        - settings_data: the current data from the Settings section\n",
    "        - path: the current path to compare (for debugging or tracking)\n",
    "        \"\"\"\n",
    "        if isinstance(d, dict):\n",
    "            # Iterate through the dictionary\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                new_path = f\"{path}/{k}\" if path else k\n",
    "                \n",
    "                # Check if the path is within the Readback or Settings section\n",
    "                if re.match(r\"/Detectors/Det\\d+/Readback\", new_path):\n",
    "                    # If the path starts with Readback, compare values from the 'Settings' section\n",
    "                    if new_path in settings_data and settings_data[new_path] == v:\n",
    "                        # If values are the same, remove them from the Settings data\n",
    "                        settings_data.pop(new_path, None)\n",
    "                    else:\n",
    "                        new_dict[k] = recurse(v, readback_data, settings_data, new_path)\n",
    "                elif re.match(r\"/Detectors/Det\\d+/Settings\", new_path):\n",
    "                    # Handle the Settings path, keep values only if different from Readback\n",
    "                    if new_path in readback_data and readback_data.get(new_path) != v:\n",
    "                        new_dict[k] = v\n",
    "                    else:\n",
    "                        # Remove from settings if matched with readback\n",
    "                        settings_data.pop(new_path, None)\n",
    "                else:\n",
    "                    new_dict[k] = recurse(v, readback_data, settings_data, new_path)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [recurse(item, readback_data, settings_data, f\"{path}[{idx}]\") for idx, item in enumerate(d)]\n",
    "        return d\n",
    "\n",
    "    # Extract readback and settings data from the main structure\n",
    "    readback_data = d.get('Detectors', {}).get('DetXX', {}).get('Readback', {})\n",
    "    settings_data = d.get('Detectors', {}).get('DetXX', {}).get('Settings', {})\n",
    "\n",
    "    # Filter out the matching values and keep differing ones\n",
    "    filtered_data = recurse(d, readback_data, settings_data)\n",
    "    #print(filtered_data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd75a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 3.999 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7912d8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('savedata1.json')\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "json2 =filter_remove_last_written(json2)\n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "json1 = read_json_from_file('savedata.json')\n",
    "json1 = filter_json_remove_slash_key(json1)\n",
    "json1 = filter_json_remove_system_keys(json1)\n",
    "json1 = filter_json_remove_legacytrigger(json1)\n",
    "json1 = filter_json_differ_Readback_Setting(json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5992a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = json_filter_remove_last_written(json2)\n",
    "json1 = json_filter_remove_last_written(json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c229e8a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (254700193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[93], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    jupyter notebook --generate-config\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebook --generate-config\n",
    "\n",
    "# c.NotebookApp.iopub_data_rate_limit = 10000000  # Increase the limit to 10 MB/s (or higher if needed)\n",
    "# c.NotebookApp.rate_limit_window = 3.0  # Optional, adjust the window time (default 3 seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c343b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_differences(start_obj, end_obj, parent_key='', differences=None):\n",
    "    if differences is None:\n",
    "        differences = {}\n",
    "\n",
    "    # Get all the unique keys from both objects\n",
    "    all_keys = set(start_obj.keys()).union(set(end_obj.keys()))\n",
    "\n",
    "    # Iterate through all keys\n",
    "    for key in all_keys:\n",
    "        # Build the current key's path\n",
    "        current_key = parent_key + key\n",
    "\n",
    "        # Case where the values are lists\n",
    "        if isinstance(start_obj.get(key), list) or isinstance(end_obj.get(key), list):\n",
    "            # Compare lists by joining them into a string for easy comparison\n",
    "            if str(start_obj.get(key)) != str(end_obj.get(key)):\n",
    "                differences[current_key] = end_obj.get(key)\n",
    "\n",
    "        # Case where the values are dictionaries\n",
    "        elif isinstance(start_obj.get(key), dict) and isinstance(end_obj.get(key), dict):\n",
    "            # Recurse into the nested dictionaries with updated parent_key\n",
    "            find_differences(start_obj.get(key), end_obj.get(key), current_key + '/', differences)\n",
    "\n",
    "        # Case where the values are primitive types (strings, numbers, etc.)\n",
    "        elif start_obj.get(key) != end_obj.get(key):\n",
    "            differences[current_key] = end_obj.get(key)\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cff4850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finddifference=find_differences(json2,json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b03ddb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 in memory after removing many keys from System expect client: 0.013 MB\n"
     ]
    }
   ],
   "source": [
    "size_in_bytes_comprehensive = asizeof.asizeof(finddifference)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024 * 1024)\n",
    "\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 in memory after removing many keys from System expect client: {size_in_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54c678eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logger/Channels/0/Statistics/Events written/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Bytes written subrun/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Bytes written/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Bytes written total/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Bytes written uncompressed/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Disk level/access_mode': 7,\n",
       " 'Logger/Channels/0/Statistics/Files written/access_mode': 7,\n",
       " 'Equipment/fridge_history/Variables/FTMP/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevE43/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory21/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevE01/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevF02/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory18/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory13/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevF03/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory24/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevF42/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory12/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory19/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory22/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevE02/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevD40/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevF01/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory10/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory10/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory10/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory10/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory10/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory16/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/Thermometry_RevF04/Variables/TEMP/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory11/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readoutSDUhistory/Variables/SDUT/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory23/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory14/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory15/Variables/RODT/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/SLOW/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/BSLN/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/SCLR/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/LIVE/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/STLE/notify_count': 1,\n",
       " 'Equipment/readouthistory20/Variables/RODT/notify_count': 1}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finddifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff14ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is changed\n",
    "\n",
    "# def find_differences(dict1, dict2, path=\"\"):  \n",
    "#     \"\"\"\n",
    "#     Recursively find differences between two nested dictionaries and format the output.\n",
    "#     \"\"\"\n",
    "#     differences = []\n",
    "    \n",
    "#     keys1, keys2 = set(dict1.keys()), set(dict2.keys())\n",
    "#     all_keys = keys1.union(keys2)\n",
    "    \n",
    "#     for key in all_keys:\n",
    "#         new_path = f\"{path}.{key}\" if path else key\n",
    "        \n",
    "#         if key not in dict1:\n",
    "#             differences.append(f\"Added: {new_path} = {dict2[key]}\")\n",
    "#         elif key not in dict2:\n",
    "#             differences.append(f\"Removed: {new_path} (was {dict1[key]})\")\n",
    "#         elif isinstance(dict1[key], dict) and isinstance(dict2[key], dict):\n",
    "#             differences.extend(find_differences(dict1[key], dict2[key], new_path))\n",
    "#         elif dict1[key] != dict2[key]:\n",
    "#             differences.append(f\"Changed: {new_path} from {dict1[key]} to {dict2[key]}\")\n",
    "    \n",
    "#     return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06725dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = filter_json_remove_slash_key(json2)\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "json2 =filter_remove_last_written(json2)\n",
    "json2 = filter_json_differ_Readback_Setting(json2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cca293c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 : 5613.97 KB\n",
      "Size of json2 remove /Key : 2869.45 KB\n",
      "Size of json2 remove system expect client: 2676.10 KB\n",
      "Size of json2 remove legacytrigger: 2676.10 KB\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('abscend.json')\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# Print size in MB with 3 decimal points\n",
    "print(f\"Size of json2 : {size_in_mb:.2f} KB\")\n",
    "\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove /Key : {size_in_mb:.2f} KB\")\n",
    "\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove system expect client: {size_in_mb:.2f} KB\")\n",
    "\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove legacytrigger: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# json2 =json_filter_remove_last_written(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove last written: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# either way is same remove \n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove settings if same as Readback: {size_in_mb:.20f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a0ebd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 remove settings if same as Readback: 5613.96875000000000000000 KB\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('abscend.json')\n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove settings if same as Readback: {size_in_mb:.20f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7faf47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of json2 remove last written: 5258.66406250000000000000 KB\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('abscend.json')\n",
    "json2 =json_filter_remove_last_written(json2)\n",
    "size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "print(f\"Size of json2 remove last written: {size_in_mb:.20f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fc892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
