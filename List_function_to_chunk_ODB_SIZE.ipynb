{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814a83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "# !pip install pympler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002080b",
   "metadata": {},
   "source": [
    "# function reading the json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451d3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "def save_json_to_file(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2a0ea",
   "metadata": {},
   "source": [
    "# removing the Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9f7f77-bf33-44b9-a348-d4f09d6e3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_slash_key(data, pattern=\"/key\"):\n",
    "    \"\"\"\n",
    "    Recursively removes keys from a dictionary if they contain the given pattern.\n",
    "    \n",
    "    :param data: Dictionary to filter.\n",
    "    :param pattern: String pattern to check in keys (default is \"/key\").\n",
    "    :return: New dictionary with filtered keys.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return data  # If data is not a dictionary, return as is\n",
    "    \n",
    "    new_dict = {}\n",
    "    for k, v in data.items():\n",
    "        if pattern not in k:  # Exclude keys that contain the pattern\n",
    "            if isinstance(v, dict):\n",
    "                new_dict[k] = filter_json_remove_slash_key(v, pattern)  # Recurse for nested dict\n",
    "            else:\n",
    "                new_dict[k] = v  # Keep the value as is\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831ee23-bb8f-41ad-ac2f-5944fb379aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = read_json_from_file('abscend.json')\n",
    "json2= filter_json_remove_slash_key(json2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23b3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_slash_key(data, pattern=\"/key\"):\n",
    "    # Create a new dictionary to store the filtered results\n",
    "    new_dict = {}\n",
    "    \n",
    "    for k, v in data.items():\n",
    "        # If the key does not contain the pattern, add it to the new dictionary\n",
    "        if pattern not in k:\n",
    "            if isinstance(v, dict):\n",
    "                # Recursively apply the function if the value is a dictionary\n",
    "                new_dict[k] = filter_json_remove_slash_key(v, pattern)\n",
    "            else:\n",
    "                # Otherwise, just add the key-value pair\n",
    "                new_dict[k] = v\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214c2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_system_keys(data):\n",
    "    # Ensure we only modify the 'System' key if it exists\n",
    "    if 'System' in data:\n",
    "        # List of keys to remove from 'System'\n",
    "        keys_to_remove = ['Buffers', 'Transition', 'Flush', 'Tmp']\n",
    "        \n",
    "        # Loop through the list and remove each key from 'System' if it exists\n",
    "        for key in keys_to_remove:\n",
    "            data['System'].pop(key, None)\n",
    "    # Filter out entries that have \"last_written\" in the key\n",
    "    if isinstance(data, list):  # Check if data is a list of dictionaries\n",
    "        data = [entry for entry in data if \"/last_written\" not in entry.get(\"key\", \"\")]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16862bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_legacytrigger(data):\n",
    "    \"\"\"\n",
    "    This function recursively removes keys that match the pattern \"/Detectors/DetXX/Settings/LegacyTrigger\".\n",
    "    \"\"\"\n",
    "    def recursive_trim(d):\n",
    "        if isinstance(d, dict):\n",
    "            # Identify keys matching the specific pattern\n",
    "            keys_to_remove = [key for key in d if \"/Detectors/Det\" in key and \"/Settings/LegacyTrigger\" in key]\n",
    "            # Remove the matching keys\n",
    "            for key in keys_to_remove:\n",
    "                del d[key]\n",
    "            # Recursively process nested dictionaries or lists\n",
    "            for key, value in d.items():\n",
    "                if isinstance(value, (dict, list)):  # If the value is a dictionary or list, apply recursion\n",
    "                    recursive_trim(value)\n",
    "\n",
    "    # Call the recursive trim function on the data\n",
    "    recursive_trim(data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9e840-9e1b-4808-ab75-b72c721780ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e78cdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing last_readout duplicate time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6edcef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_data_remove_duplicate_last_written1(data):\n",
    "#     seen_values = set()  # Stores unique \"last_written\" values\n",
    "\n",
    "#     def recurse(d):\n",
    "#         if isinstance(d, dict):\n",
    "#             new_dict = {}\n",
    "#             for k, v in d.items():\n",
    "#                 if isinstance(v, dict) and \"last_written\" in v:\n",
    "#                     last_written_val = v[\"last_written\"]\n",
    "#                     if last_written_val not in seen_values:\n",
    "#                         seen_values.add(last_written_val)\n",
    "#                         new_dict[k] = v  # Keep the first occurrence\n",
    "#                 else:\n",
    "#                     # Recursively process nested dictionaries and lists\n",
    "#                     new_dict[k] = recurse(v)\n",
    "#             return new_dict\n",
    "#         elif isinstance(d, list):\n",
    "#             return [recurse(item) for item in d]\n",
    "#         return d\n",
    "\n",
    "#     # First pass to collect duplicates\n",
    "#     filtered_data = recurse(data)\n",
    "\n",
    "#     return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36575e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json2 = read_json_from_file('savedata.json')\n",
    "\n",
    "# json2 = filter_json_remove_slash_key(json2)\n",
    "\n",
    "\n",
    "# json2 = filter_json_remove_system_keys(json2)\n",
    "\n",
    "\n",
    "# json2 = filter_json_remove_legacytrigger(json2)\n",
    "\n",
    "\n",
    "# json2 = json_filter_remove_last_written(json2)\n",
    "# save_json_to_file(json2, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc068403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively remove keys ending with \"last_written\"\n",
    "def json_filter_remove_last_written(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: json_filter_remove_last_written(v) for k, v in data.items() if not k.endswith(\"last_written\")}\n",
    "    elif isinstance(data, list):\n",
    "        return [json_filter_remove_last_written(item) for item in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d620202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_json_differ_Readback_Setting(d):\n",
    "    \"\"\"\n",
    "    Filters out keys from the 'Settings' section of Detectors/DetXX if they match the values in the 'Readback' section.\n",
    "    Keeps the keys that differ between the 'Settings' and 'Readback' paths.\n",
    "    \"\"\"\n",
    "    def recurse(d, readback_data, settings_data, path=\"\"):\n",
    "        \"\"\"\n",
    "        Recursive function to traverse and compare the two paths.\n",
    "        - d: the current data (settings or readback)\n",
    "        - readback_data: the current data from the Readback section\n",
    "        - settings_data: the current data from the Settings section\n",
    "        - path: the current path to compare (for debugging or tracking)\n",
    "        \"\"\"\n",
    "        if isinstance(d, dict):\n",
    "            # Iterate through the dictionary\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                new_path = f\"{path}/{k}\" if path else k\n",
    "                \n",
    "                # Check if the path is within the Readback or Settings section\n",
    "                if re.match(r\"/Detectors/Det\\d+/Readback\", new_path):\n",
    "                    # If the path starts with Readback, compare values from the 'Settings' section\n",
    "                    if new_path in settings_data and settings_data[new_path] == v:\n",
    "                        # If values are the same, remove them from the Settings data\n",
    "                        settings_data.pop(new_path, None)\n",
    "                    else:\n",
    "                        new_dict[k] = recurse(v, readback_data, settings_data, new_path)\n",
    "                elif re.match(r\"/Detectors/Det\\d+/Settings\", new_path):\n",
    "                    # Handle the Settings path, keep values only if different from Readback\n",
    "                    if new_path in readback_data and readback_data.get(new_path) != v:\n",
    "                        new_dict[k] = v\n",
    "                    else:\n",
    "                        # Remove from settings if matched with readback\n",
    "                        settings_data.pop(new_path, None)\n",
    "                else:\n",
    "                    new_dict[k] = recurse(v, readback_data, settings_data, new_path)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [recurse(item, readback_data, settings_data, f\"{path}[{idx}]\") for idx, item in enumerate(d)]\n",
    "        return d\n",
    "\n",
    "    # Extract readback and settings data from the main structure\n",
    "    readback_data = d.get('Detectors', {}).get('DetXX', {}).get('Readback', {})\n",
    "    settings_data = d.get('Detectors', {}).get('DetXX', {}).get('Settings', {})\n",
    "\n",
    "    # Filter out the matching values and keep differing ones\n",
    "    filtered_data = recurse(d, readback_data, settings_data)\n",
    "    #print(filtered_data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a2c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_differences(start_obj, end_obj, parent_key='', differences=None):\n",
    "#     if differences is None:\n",
    "#         differences = {}\n",
    "\n",
    "#     # Get all the unique keys from both objects\n",
    "#     all_keys = set(start_obj.keys()).union(set(end_obj.keys()))\n",
    "\n",
    "#     # Iterate through all keys\n",
    "#     for key in all_keys:\n",
    "#         # Build the current key's path\n",
    "#         current_key = parent_key + key\n",
    "\n",
    "#         # Case where the values are lists\n",
    "#         if isinstance(start_obj.get(key), list) or isinstance(end_obj.get(key), list):\n",
    "#             # Compare lists by joining them into a string for easy comparison\n",
    "#             if str(start_obj.get(key)) != str(end_obj.get(key)):\n",
    "#                 differences[current_key] = end_obj.get(key)\n",
    "\n",
    "#         # Case where the values are dictionaries\n",
    "#         elif isinstance(start_obj.get(key), dict) and isinstance(end_obj.get(key), dict):\n",
    "#             # Recurse into the nested dictionaries with updated parent_key\n",
    "#             find_differences(start_obj.get(key), end_obj.get(key), current_key + '/', differences)\n",
    "\n",
    "#         # Case where the values are primitive types (strings, numbers, etc.)\n",
    "#         elif start_obj.get(key) != end_obj.get(key):\n",
    "#             differences[current_key] = end_obj.get(key)\n",
    "\n",
    "#     return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcaff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_differences(start_obj, end_obj):\n",
    "    def recursive_diff(start, end):\n",
    "        diff = {}\n",
    "        for key in end.keys():\n",
    "            if key not in start:\n",
    "                # Key is new in end_obj\n",
    "                diff[key] = end[key]\n",
    "            elif isinstance(start[key], dict) and isinstance(end[key], dict):\n",
    "                # Recursively check nested dictionaries\n",
    "                nested_diff = recursive_diff(start[key], end[key])\n",
    "                if nested_diff:  # Only add if there are differences\n",
    "                    diff[key] = nested_diff\n",
    "            elif isinstance(start[key], list) and isinstance(end[key], list):\n",
    "                # Compare lists directly\n",
    "                if start[key] != end[key]:\n",
    "                    diff[key] = end[key]\n",
    "            elif start[key] != end[key]:\n",
    "                # Value has changed\n",
    "                diff[key] = end[key]\n",
    "        return diff\n",
    "\n",
    "    return recursive_diff(start_obj, end_obj)\n",
    "# differences = find_differences(start_json, end_json)\n",
    "# print(differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8716ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = read_json_from_file('savedata1.json')\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "json2 = json_filter_remove_last_written(json2)\n",
    "# json2 = filter_json_differ_Readback_Setting(json2)\n",
    "json1 = read_json_from_file('savedata.json')\n",
    "json1 = filter_json_remove_slash_key(json1)\n",
    "json1 = filter_json_remove_system_keys(json1)\n",
    "json1 = json_filter_remove_last_written(json1)\n",
    "# json1 = filter_json_differ_Readback_Setting(json1)\n",
    "finddifference=find_differences(json2,json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545af90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logger': {'Channels': {'0': {'Statistics': {'Disk level': {'access_mode': 7},\n",
       "     'Bytes written': {'access_mode': 7},\n",
       "     'Files written': {'access_mode': 7},\n",
       "     'Events written': {'access_mode': 7},\n",
       "     'Bytes written total': {'access_mode': 7},\n",
       "     'Bytes written subrun': {'access_mode': 7},\n",
       "     'Bytes written uncompressed': {'access_mode': 7}}}}},\n",
       " 'Equipment': {'fridge_history': {'Variables': {'FTMP': {'notify_count': 1}}},\n",
       "  'readouthistory10': {'Variables': {'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory11': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory12': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory13': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory14': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory15': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory16': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory18': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory19': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory20': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory21': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory22': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory23': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readouthistory24': {'Variables': {'BSLN': {'notify_count': 1},\n",
       "    'LIVE': {'notify_count': 1},\n",
       "    'RODT': {'notify_count': 1},\n",
       "    'SCLR': {'notify_count': 1},\n",
       "    'SLOW': {'notify_count': 1},\n",
       "    'STLE': {'notify_count': 1}}},\n",
       "  'readoutSDUhistory': {'Variables': {'SDUT': {'notify_count': 1}}},\n",
       "  'Thermometry_RevD40': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevE01': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevE02': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevE43': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevF01': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevF02': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevF03': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevF04': {'Variables': {'TEMP': {'notify_count': 1}}},\n",
       "  'Thermometry_RevF42': {'Variables': {'TEMP': {'notify_count': 1}}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finddifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ccd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = read_json_from_file('savedata1.json')\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "json2 = json_filter_remove_last_written(json2)\n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "json1 = read_json_from_file('savedata.json')\n",
    "json1 = filter_json_remove_slash_key(json1)\n",
    "json1 = filter_json_remove_system_keys(json1)\n",
    "json1 = json_filter_remove_last_written(json1)\n",
    "json1 = filter_json_differ_Readback_Setting(json1)\n",
    "finddifference3=find_differences(json2,json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json2 = filter_json_remove_slash_key(json2)\n",
    "# json2 = filter_json_remove_system_keys(json2)\n",
    "# json2 = filter_json_remove_legacytrigger(json2)\n",
    "# json2 =filter_remove_last_written(json2)\n",
    "# json2 = filter_json_differ_Readback_Setting(json2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f64c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Disk space its memory not relevant\n",
    "# json2 = read_json_from_file('savedata1.json')\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# # Print size in MB with 3 decimal points\n",
    "# print(f\"Size of json2 : {size_in_mb:.2f} KB\")\n",
    "\n",
    "# json2 = filter_json_remove_slash_key(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove /Key : {size_in_mb:.2f} KB\")\n",
    "\n",
    "# json2 = filter_json_remove_system_keys(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove system expect client: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# json2 = filter_json_remove_legacytrigger(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove legacytrigger: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# json2 =json_filter_remove_last_written(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove last written: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# # either way is same remove  not needed\n",
    "# json2 = filter_json_differ_Readback_Setting(json2)\n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(json2)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove settings if Readback is same as Detectors/DetXX: {size_in_mb:.2f} KB\")\n",
    "\n",
    "# # either way is same remove \n",
    "# size_in_bytes_comprehensive = asizeof.asizeof(finddifference3)\n",
    "# size_in_mb = size_in_bytes_comprehensive / (1024)\n",
    "# print(f\"Size of json2 remove if start is same as stop: {size_in_mb:.2f} KB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e998be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving Json\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('savedata.json')\n",
    "\n",
    "json2 = filter_json_remove_slash_key(json2)\n",
    "save_json_to_file(json2, \"savedata_2_removed_slash_key.json\")\n",
    "\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "save_json_to_file(json2, \"savedata_3_removed_system_keys.json\")\n",
    "\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "save_json_to_file(json2, \"savedata_4_removed_legacytrigger.json\")\n",
    "\n",
    "json2 = json_filter_remove_last_written(json2)\n",
    "save_json_to_file(json2, \"savedata_5_removed_last_written.json\")\n",
    "\n",
    "json2 = filter_json_differ_Readback_Setting(json2)\n",
    "save_json_to_file(json2, \"savedata_6_removed_readback_setting.json\")\n",
    "\n",
    "\n",
    "save_json_to_file(finddifference, \"finddifference.json\")\n",
    "\n",
    "print(\"saving Json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7f4ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                     Disk Size (KB)\n",
      "============================================================\n",
      "savedata.json_start_original                         5306.39\n",
      "savedata.json_end_original                           5306.39\n",
      "savedata_2_removed_slash_key.json                    3899.05\n",
      "savedata_3_removed_system_keys.json                  2769.13\n",
      "savedata_4_removed_legacytrigger.json                2769.13\n",
      "savedata_5_removed_last_written.json                 2052.64\n",
      "savedata_6_removed_readback_setting.json             2052.64\n",
      "difference in end ODB than start                        7.77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file names corresponding to each step with sizes in KB\n",
    "file_sizes_on_disk = {\n",
    "    \"savedata.json_start_original\": 5433740/1024,\n",
    "    \"savedata.json_end_original\": 5433740 / 1024,\n",
    "    \"savedata_2_removed_slash_key.json\": 3992631 / 1024,\n",
    "    \"savedata_3_removed_system_keys.json\": 2835593 / 1024,\n",
    "    \"savedata_4_removed_legacytrigger.json\": 2835593 / 1024,\n",
    "    \"savedata_5_removed_last_written.json\": 2101905 / 1024,\n",
    "    \"savedata_6_removed_readback_setting.json\": 2101905 / 1024,\n",
    "    \"difference in end ODB than start\" : 7955/1024\n",
    "}\n",
    "\n",
    "# Print table header\n",
    "print(f\"{'File Name':<40}{'Disk Size (KB)':>20}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Print each file's disk size\n",
    "for file_name, size_kb in file_sizes_on_disk.items():\n",
    "    print(f\"{file_name:<40}{size_kb:>20.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351589e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
